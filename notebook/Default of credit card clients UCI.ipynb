{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default of credit card clients Data Set\n",
    "\n",
    "### Data Set Information:\n",
    "\n",
    "This research aimed at the case of customersâ€™ default payments in Taiwan and compares the predictive accuracy of probability of default among six data mining methods. From the perspective of risk management, the result of predictive accuracy of the estimated probability of default will be more valuable than the binary result of classification - credible or not credible clients. Because the real probability of default is unknown, this study presented the novel â€œSorting Smoothing Methodâ€ to estimate the real probability of default. With the real probability of default as the response variable (Y), and the predictive probability of default as the independent variable (X), the simple linear regression result (Y = A + BX) shows that the forecasting model produced by artificial neural network has the highest coefficient of determination; its regression intercept (A) is close to zero, and regression coefficient (B) to one. Therefore, among the six data mining techniques, artificial neural network is the only one that can accurately estimate the real probability of default.\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "This research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable. This study reviewed the literature and used the following 23 variables as explanatory variables:\n",
    "\n",
    "X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.\n",
    "X2: Gender (1 = male; 2 = female).\n",
    "X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).\n",
    "X4: Marital status (1 = married; 2 = single; 3 = others).\n",
    "X5: Age (year).\n",
    "X6 - X11: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: \n",
    "  X6 = the repayment status in September, 2005; \n",
    "  X7 = the repayment status in August, 2005; \n",
    "  . . .;\n",
    "  X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.\n",
    "X12-X17: Amount of bill statement (NT dollar). \n",
    "  X12 = amount of bill statement in September, 2005; \n",
    "  X13 = amount of bill statement in August, 2005; \n",
    "  . . .; \n",
    "  X17 = amount of bill statement in April, 2005.\n",
    "X18-X23: Amount of previous payment (NT dollar). \n",
    "  X18 = amount paid in September, 2005; \n",
    "  X19 = amount paid in August, 2005; \n",
    "  . . .;\n",
    "  X23 = amount paid in April, 2005.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import requests\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "URL = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\n",
    "\n",
    "def fetch_data(fname='default_of_credit_card_clients.xls'):\n",
    "    \"\"\"\n",
    "    Helper method to retreive the ML Repository dataset.\n",
    "    \"\"\"\n",
    "    response = requests.get(URL)\n",
    "    outpath  = os.path.abspath(fname)\n",
    "    with open(outpath, 'w') as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    return outpath\n",
    "\n",
    "# Fetch the data if required\n",
    "# DATA = fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 ID       LIMIT_BAL           SEX     EDUCATION      MARRIAGE  \\\n",
      "count  30000.000000    30000.000000  30000.000000  30000.000000  30000.000000   \n",
      "mean   15000.500000   167484.322667      1.603733      1.853133      1.551867   \n",
      "std     8660.398374   129747.661567      0.489129      0.790349      0.521970   \n",
      "min        1.000000    10000.000000      1.000000      0.000000      0.000000   \n",
      "25%     7500.750000    50000.000000      1.000000      1.000000      1.000000   \n",
      "50%    15000.500000   140000.000000      2.000000      2.000000      2.000000   \n",
      "75%    22500.250000   240000.000000      2.000000      2.000000      2.000000   \n",
      "max    30000.000000  1000000.000000      2.000000      6.000000      3.000000   \n",
      "\n",
      "                AGE         PAY_0         PAY_2         PAY_3         PAY_4  \\\n",
      "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
      "mean      35.485500     -0.016700     -0.133767     -0.166200     -0.220667   \n",
      "std        9.217904      1.123802      1.197186      1.196868      1.169139   \n",
      "min       21.000000     -2.000000     -2.000000     -2.000000     -2.000000   \n",
      "25%       28.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
      "50%       34.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%       41.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "max       79.000000      8.000000      8.000000      8.000000      8.000000   \n",
      "\n",
      "           ...           BILL_AMT3      BILL_AMT4      BILL_AMT5  \\\n",
      "count      ...        3.000000e+04   30000.000000   30000.000000   \n",
      "mean       ...        4.701315e+04   43262.948967   40311.400967   \n",
      "std        ...        6.934939e+04   64332.856134   60797.155770   \n",
      "min        ...       -1.572640e+05 -170000.000000  -81334.000000   \n",
      "25%        ...        2.666250e+03    2326.750000    1763.000000   \n",
      "50%        ...        2.008850e+04   19052.000000   18104.500000   \n",
      "75%        ...        6.016475e+04   54506.000000   50190.500000   \n",
      "max        ...        1.664089e+06  891586.000000  927171.000000   \n",
      "\n",
      "           BILL_AMT6       PAY_AMT1      PAY_AMT2      PAY_AMT3  \\\n",
      "count   30000.000000   30000.000000  3.000000e+04   30000.00000   \n",
      "mean    38871.760400    5663.580500  5.921163e+03    5225.68150   \n",
      "std     59554.107537   16563.280354  2.304087e+04   17606.96147   \n",
      "min   -339603.000000       0.000000  0.000000e+00       0.00000   \n",
      "25%      1256.000000    1000.000000  8.330000e+02     390.00000   \n",
      "50%     17071.000000    2100.000000  2.009000e+03    1800.00000   \n",
      "75%     49198.250000    5006.000000  5.000000e+03    4505.00000   \n",
      "max    961664.000000  873552.000000  1.684259e+06  896040.00000   \n",
      "\n",
      "            PAY_AMT4       PAY_AMT5       PAY_AMT6  \n",
      "count   30000.000000   30000.000000   30000.000000  \n",
      "mean     4826.076867    4799.387633    5215.502567  \n",
      "std     15666.159744   15278.305679   17777.465775  \n",
      "min         0.000000       0.000000       0.000000  \n",
      "25%       296.000000     252.500000     117.750000  \n",
      "50%      1500.000000    1500.000000    1500.000000  \n",
      "75%      4013.250000    4031.500000    4000.000000  \n",
      "max    621000.000000  426529.000000  528666.000000  \n",
      "\n",
      "[8 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT - Issue saving xls file needed to be fix in fetch_data. Using a valid manually downloaded files instead for this example.\n",
    "\n",
    "DATA = \"./default_of_credit_card_clients2.xls\"\n",
    "\n",
    "FEATURES  = [\n",
    "    \"ID\",\n",
    "    \"LIMIT_BAL\",\n",
    "    \"SEX\",\n",
    "    \"EDUCATION\",\n",
    "    \"MARRIAGE\",\n",
    "    \"AGE\",\n",
    "    \"PAY_0\",\n",
    "    \"PAY_2\",\n",
    "    \"PAY_3\",\n",
    "    \"PAY_4\",\n",
    "    \"PAY_5\",\n",
    "    \"PAY_6\",\n",
    "    \"BILL_AMT1\",\n",
    "    \"BILL_AMT2\",\n",
    "    \"BILL_AMT3\",\n",
    "    \"BILL_AMT4\",\n",
    "    \"BILL_AMT5\",\n",
    "    \"BILL_AMT6\",\n",
    "    \"PAY_AMT1\",\n",
    "    \"PAY_AMT2\",\n",
    "    \"PAY_AMT3\",\n",
    "    \"PAY_AMT4\",\n",
    "    \"PAY_AMT5\",\n",
    "    \"PAY_AMT6\",\n",
    "    \"label\"  \n",
    "]\n",
    "\n",
    "LABEL_MAP = {\n",
    "    1: \"Yes\",\n",
    "    0: \"No\",\n",
    "}\n",
    "\n",
    "# Read the data into a DataFrame\n",
    "df = pd.read_excel(DATA,header=None, skiprows=2, names=FEATURES)\n",
    "\n",
    "# Convert class labels into text\n",
    "for k,v in LABEL_MAP.items():\n",
    "    df.ix[df.label == k, 'label'] = v\n",
    "\n",
    "# Describe the dataset\n",
    "print df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
       "1   2     120000    2          2         2   26     -1      2      0      0   \n",
       "2   3      90000    2          2         2   34      0      0      0      0   \n",
       "3   4      50000    2          2         1   37      0      0      0      0   \n",
       "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   ...    BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...            0          0          0         0       689         0   \n",
       "1  ...         3272       3455       3261         0      1000      1000   \n",
       "2  ...        14331      14948      15549      1518      1500      1000   \n",
       "3  ...        28314      28959      29547      2000      2019      1200   \n",
       "4  ...        20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  label  \n",
       "0         0         0         0    Yes  \n",
       "1      1000         0      2000    Yes  \n",
       "2      1000      1000      5000     No  \n",
       "3      1100      1069      1000     No  \n",
       "4      9000       689       679     No  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 instances with 25 features\n",
      "\n",
      "label\n",
      "No     23364\n",
      "Yes     6636\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Determine the shape of the data\n",
    "print \"{} instances with {} features\\n\".format(*df.shape)\n",
    "\n",
    "# Determine the frequency of each class\n",
    "print df.groupby('label')['label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix\n",
    "scatter_matrix(df, alpha=0.2, figsize=(12, 12), diagonal='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import parallel_coordinates\n",
    "plt.figure(figsize=(12,12))\n",
    "parallel_coordinates(df, 'label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import radviz\n",
    "plt.figure(figsize=(12,12))\n",
    "radviz(df, 'label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction \n",
    "\n",
    "One way that we can structure our data for easy management is to save files on disk. The Scikit-Learn datasets are already structured this way, and when loaded into a `Bunch` (a class imported from the `datasets` module of Scikit-Learn) we can expose a data API that is very familiar to how we've trained on our toy datasets in the past. A `Bunch` object exposes some important properties:\n",
    "\n",
    "- **data**: array of shape `n_samples` * `n_features`\n",
    "- **target**: array of length `n_samples`\n",
    "- **feature_names**: names of the features\n",
    "- **target_names**: names of the targets\n",
    "- **filenames**: names of the files that were loaded\n",
    "- **DESCR**: contents of the readme\n",
    "\n",
    "**Note**: This does not preclude database storage of the data, in fact - a database can be easily extended to load the same `Bunch` API. Simply store the README and features in a dataset description table and load it from there. The filenames property will be redundant, but you could store a SQL statement that shows the data load. \n",
    "\n",
    "In order to manage our data set _on disk_, we'll structure our data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./../data/cc_default/meta.json', 'w') as f:\n",
    "        meta = {'feature_names': FEATURES, 'target_names': LABEL_MAP}\n",
    "        json.dump(meta, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.base import Bunch\n",
    "\n",
    "DATA_DIR = os.path.abspath(os.path.join(\".\", \"..\", \"data\", \"cc_default\"))\n",
    "\n",
    "# Show the contents of the data directory\n",
    "for name in os.listdir(DATA_DIR):\n",
    "    if name.startswith(\".\"): continue\n",
    "    print \"- {}\".format(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(root=DATA_DIR):\n",
    "    # Construct the `Bunch` for the wheat dataset\n",
    "    filenames     = {\n",
    "        'meta': os.path.join(root, 'meta.json'),\n",
    "        'rdme': os.path.join(root, 'README.md'),\n",
    "        'data_xls': os.path.join(root, 'default_of_credit_card_clients.xls'),\n",
    "        'data': os.path.join(root, 'default_of_credit_card_clients.csv'),\n",
    "    }\n",
    "\n",
    "    # Load the meta data from the meta json\n",
    "    with open(filenames['meta'], 'r') as f:\n",
    "        meta = json.load(f)\n",
    "        target_names  = meta['target_names']\n",
    "        feature_names = meta['feature_names']\n",
    "\n",
    "    # Load the description from the README. \n",
    "    with open(filenames['rdme'], 'r') as f:\n",
    "        DESCR = f.read()\n",
    "\n",
    "    # Load the dataset from the EXCEL file.\n",
    "    df = pd.read_excel(filenames['data_xls'],header=None, skiprows=2, names=FEATURES)\n",
    "    df.to_csv(filenames['data'],header=False)\n",
    "    dataset = np.loadtxt(filenames['data'],delimiter=\",\")\n",
    "\n",
    "    # Extract the target from the data\n",
    "    data   = dataset[:, 0:-1]\n",
    "    target = dataset[:, -1]\n",
    "\n",
    "    # Create the bunch object\n",
    "    return Bunch(\n",
    "        data=data,\n",
    "        target=target,\n",
    "        filenames=filenames,\n",
    "        target_names=target_names,\n",
    "        feature_names=feature_names,\n",
    "        DESCR=DESCR\n",
    "    )\n",
    "\n",
    "# Save the dataset as a variable we can use.\n",
    "dataset = load_data()\n",
    "\n",
    "print dataset.data.shape\n",
    "print dataset.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification \n",
    "\n",
    "Now that we have a dataset `Bunch` loaded and ready, we can begin the classification process. Let's attempt to build a classifier with kNN, SVM, and Random Forest classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_and_evaluate(dataset, model, label, **kwargs):\n",
    "    \"\"\"\n",
    "    Because of the Scikit-Learn API, we can create a function to\n",
    "    do all of the fit and evaluate work on our behalf!\n",
    "    \"\"\"\n",
    "    start  = time.time() # Start the clock! \n",
    "    scores = {'precision':[], 'recall':[], 'accuracy':[], 'f1':[]}\n",
    "    \n",
    "    for train, test in KFold(dataset.data.shape[0], n_folds=12, shuffle=True):\n",
    "        X_train, X_test = dataset.data[train], dataset.data[test]\n",
    "        y_train, y_test = dataset.target[train], dataset.target[test]\n",
    "        \n",
    "        estimator = model(**kwargs)\n",
    "        estimator.fit(X_train, y_train)\n",
    "        \n",
    "        expected  = y_test\n",
    "        predicted = estimator.predict(X_test)\n",
    "        \n",
    "        # Append our scores to the tracker\n",
    "        scores['precision'].append(metrics.precision_score(expected, predicted, average=\"weighted\"))\n",
    "        scores['recall'].append(metrics.recall_score(expected, predicted, average=\"weighted\"))\n",
    "        scores['accuracy'].append(metrics.accuracy_score(expected, predicted))\n",
    "        scores['f1'].append(metrics.f1_score(expected, predicted, average=\"weighted\"))\n",
    "\n",
    "    # Report\n",
    "    print \"Build and Validation of {} took {:0.3f} seconds\".format(label, time.time()-start)\n",
    "    print \"Validation scores are as follows:\\n\"\n",
    "    print pd.DataFrame(scores).mean()\n",
    "    \n",
    "    # Write official estimator to disk\n",
    "    estimator = model(**kwargs)\n",
    "    estimator.fit(dataset.data, dataset.target)\n",
    "    \n",
    "    outpath = label.lower().replace(\" \", \"-\") + \".pickle\"\n",
    "    with open(outpath, 'w') as f:\n",
    "        pickle.dump(estimator, f)\n",
    "\n",
    "    print \"\\nFitted model written to:\\n{}\".format(os.path.abspath(outpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perform SVC Classification\n",
    "#fit_and_evaluate(dataset, SVC, \"CC Defaut - SVM Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform kNN Classification\n",
    "fit_and_evaluate(dataset, KNeighborsClassifier, \"CC Defaut - kNN Classifier\", n_neighbors=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform Random Forest Classification\n",
    "fit_and_evaluate(dataset, RandomForestClassifier, \"CC Defaut - Random Forest Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
